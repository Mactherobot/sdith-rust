\documentclass[twoside,11pt,openright]{report}

\usepackage[latin1]{inputenc}
\usepackage[american]{babel}
\usepackage{a4}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage[fleqn]{amsmath}
\usepackage{epsfig}
\usepackage[T1]{fontenc}
\usepackage{mathptmx}
\usepackage{color}
\usepackage{epstopdf}
\usepackage{microtype}
\usepackage{hyperref}
\usepackage[useregional]{datetime2}
\DTMlangsetup[en-US]{showdayofmonth=false}
\usepackage{lipsum}
\usepackage{ctable} % for \specialrule command

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newcommand{\definitionautorefname}{Definition}


\theoremstyle{plain}
\newtheorem{lemma}{Lemma}[section]

\renewcommand*\sfdefault{lmss}
\renewcommand*\ttdefault{txtt}

\newcommand{\todo}[1]{{\color[rgb]{.5,0,0}\textbf{$\blacktriangleright$#1$\blacktriangleleft$}}}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagestyle{empty}
\pagenumbering{roman}
\vspace*{\fill}\noindent{\rule{\linewidth}{1mm}\\[4ex]
{\Huge\sf SD-in-the-Head rust implementation and optimization}\\[2ex]
{\huge\sf Hugh Benjamin Zachariae, 201508592 \\ Magnus Jensen,
201708626}\\[2ex]
\noindent\rule{\linewidth}{1mm}\\[4ex]
\noindent{\Large\sf Master's Thesis, Computer Science\\[1ex]
  \today \\[1ex] Advisor: Diego F. Aranha\\[15ex]}\\[\fill]}
\epsfig{file=logo.eps}\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagestyle{plain}
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

\todo{in English\dots}

\chapter*{Resum\'e}
\addcontentsline{toc}{chapter}{Resum\'e}

\todo{in Danish\dots}

\chapter*{Acknowledgments}
\addcontentsline{toc}{chapter}{Acknowledgments}

\todo{\dots}

\vspace{2ex}
\begin{flushright}
  \emph{Magnus Jensen,}\\
  \emph{Aarhus, \today.}
\end{flushright}

\tableofcontents
\cleardoublepage
\pagenumbering{arabic}
\setcounter{secnumdepth}{2}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{ch:intro}

few pages. Introduce what we have done and how the paper is structured

\todo{motivate and explain the problem to be addressed}

\todo{example of a citation: \cite{DBLP:conf/sas/ChristensenMS03}}
\todo{get your bibtex entries from \url{https://dblp.org/}}

\todo{describe how we progressed through the project in an interesting way. What did we set out to do, what were the hurdles.}

\todo{contributions: rust, issues we found.}

\section{Post-Quantum Cryptography and the NIST call to action}
\label{sec:quantum}

In 1994, the discovery of Shor's algorithm~\cite{shor1997}, provided a polynomial time algorithm for factoring integers and computing discrete logarithms using quantum computing. Back then, quantum computers where theories on paper. However, two decades later, significant developments in quantum technology, has brought us dangerously close to the point where quantum computers can solve foundational problems, which would break the security of modern standards of public-key cryptosystems. For example the Diffie-Hellman key exchange standard X25519, used in TLSv1.3, is not post-quantum secure.

In 2016, the National Institute of Standards and Technology (NIST), known for standardizing cryptographic primitives like AES and SHA, initiated a call for quantum resistant public-key cryptosystems~\cite{nistcall}. This let to the standardization of three signature schemes, namely Dilithium~\cite{ducas2018crystals}, Falcon~\cite{fouque2018falcon} and SPHINCS+~\cite{bernstein2019sphincs+}. All three of the schemes are based on the hardness of structured lattice problems. This has led to the most recent call in 2022 for additional quantum resistant signature schemes based on different assumptions to diversify the standards available for the future.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Mathematical preliminaries}
\label{ch:desc}

Abstract level description of the algorithm own words
MPCitH
Syndrome detection problem
Fiat-Shamir heuristic

\todo{Maybe write out the reduction to three dimensional matching problem}
\section{Syndrome Decoding Problem}
\label{sec:syndrome}
The basis for the SD-in-the-Head protocol is to use the Syndrome Decoding (SD) problem in order to proove that the signature is correct.
It uses the NP-complete \textit{coset weights} problem, which was defined in 1978 by Berlekamp and McEliece \cite{berlekamp1978inherent}. 
We define it in the following way:
\begin{definition}
  \label{def:syndrome}
  Given $H \in \mathbb{F}^{(m-k)\times m}_q$ and $y \in \mathbb{F}^{m-k}_q$. The problem is to find $x \in \mathbb{F}^m_q$ s.t. wt$(x) = w$ and $Hx = y$.
\end{definition}

To generate such an instance one can simply draw uniformly at random a matrix $H$ and a code word $x$ (with $wt(x) \leq w$), and then calculate the syndrome $y = Hx$.

\subsubsection{Standard form of the parity-check matrix}\label{sec:standard_form_of_the_parity_check_matrix} 
The protocol utilizes the fact that we can represent the matrix $H$ in standard form. $H = (H'|I_{m-k}) $ Where $H' \in \mathbb{F}^{(m-k)\times k}_q$.
\\
This allows for the following representation of the syndrome:
\begin{equation}
  y = Hx = H'x_a + x_b
  \label{eq:standard_form_of_the_parity_check_matrix}
\end{equation}
with $x = (x_a | x_b)$.
Which gives two properties:
\begin{itemize}
  \item At the MPC layer, we only need to reveal one share $x_a$. Due to the fact that the other share $x_b$ can simply be recomputed by $x_b = y - H'x_a$.
  \item By linearity of the above relation one only needs to send $x_a$ in order to recover the SD instance. So from a sharing of $x_a$ one can check the correctness of the SD instance.
\end{itemize}

\subsubsection{Polynomial representation of SD}\label{sec:polynomial_representation} 
The SD-in-the-Head protocol is based on three (witness-dependent) polynomials $S, Q$ and $P$, and one public polynomial $F$.
These are used for checking the correctness of the SD solution by verifying the following relation:
\begin{equation}
  S\cdot Q = P\cdot F
  \label{eq:polynomial_representation}
\end{equation}
Let $f_1,\dots, f_q$ denote elements of $\mathbb{F}_q$, then the polynomials are defined as:
\begin{itemize}
  \item $S\in \mathbb{F}_q[X]$ is the Lagrange interpolation of the coordinates of $x$, such that it matches $S(f_i) = x_i$ for $i\in [1:m]$ and has degree $deg(S) \leq m-1$ 
  \item $Q\in \mathbb{F}_q[X]$ is defined by $Q(X) = \prod_{i\in E}(X - f_i)$. $E \subset [1:m]$ with order $|E| = w$, such that $E$ contains the non-zero coordinates of $x$. $Q$ has degree $deg(Q) = w$.
  \item $P\in \mathbb{F}_q[X]$ is defined as $P = S\cdot Q/F$ and has degree $deg(P) \leq w-1$. By definition the polynomial $F$ divides $S\cdot Q$.
  \item $F\in \mathbb{F}_q[X]$ is the \textit{vanishing polynomial} of the set ${f_1, \dots, f_m}$ also defined as $F(X) = \prod_{i\in [1:m]}(X - f_i)$ and has degree $deg(F) = m$.
\end{itemize}
We can now look at the relation in \autoref{eq:polynomial_representation}. If we look at the left-hand side, which has the following property by design $S\cdot Q(f_i) = 0 \;\forall\; f_i \in [1:m]$. This comes from the fact that the polynomial $S(f_i)$ is zero whenever $x_i = 0$, this follows from the fact that it is the lagrange interpolation of $x$. And that the polynomial $Q(f_i)$ is zero whenever $f_i$ is a non-zero coordinate of $x$. 
For the right-hand side, the polynomial $F$ is the vanishing polynomial for the set ${f_1, \dots, f_m}$, so $F(f_i) = 0 \;\forall\; f_i \in [1:m]$. The polynomial $P$ is needed to match the degree of $S\cdot Q$. As the degree of $F$ is $m \leq deg(S\cdot Q) \leq m + w - 1$. It is now apparent that if the prover can convince the verifier that they know of polynomials $P,Q$ such that $S\cdot Q = F /cdot P = 0$ at all points $f_i \in [1:m]$. The following must hold, either $S(f_i) = x_i = 0$ or $Q(f_i) = 0$. The polynomial Q can be zero in at most $w$ points based on the degree, this means that S is non-zero in at most $w$ points, based on the construction. This entails that $x$ has weight as most $w$. 

We can now define the soundness of the MPC protocol as follows:

\begin{equation}
  wt(x) \leq w \Leftrightarrow \exists P,Q \text{  with  }deg(P)\leq w-1\text{  and  }deg(Q) = w\text{  s.t.  }\autoref{eq:polynomial_representation} \text{  holds}
  \label{eq:soundness}
\end{equation}
This comes from the definition of the polynomial $Q$. We can now share a witness $(x_a, Q, P)$. Now based on the \autoref{eq:standard_form_of_the_parity_check_matrix} relation, the $x$ can be locally computed along with the polynomial $S$, this can then be used to run an equality test for the relation $S \cdot Q = P \cdot F$.

\subsection{Equality test}\label{sub:equality_test} 
\todo{Write about the equality test}


% subsection  (end)
\section{Galois Finite Field}
\label{sec:gf256}
The protocol uses po

This paper \cite{brownadvanced} describes the mathematical model around the galois field $GF(2^8)$.

In order to define addition and multiplication within the galois field. The bytes are represented as polynomials of the form:
\begin{equation}
  \label{eq:poly}
  p(x) = p_7x^7 + p_6x^6 + p_5x^5 + p_4x^4 + p_3x^3 + p_2x^2 + p_1x + p_0
\end{equation}
This gives a representation of the byte: ${00011101}$ to be:
\begin{equation}
  \label{eq:example_poly}
  00011101 = p_4x^4 + p_3x^3 + p_2x^2 + p_0
\end{equation}


\section{Addition}
\section{Multiplication}

A group for bytes

\todo{Describe the arithmetic operations in GF256 and the extension field}


\subsection{Extension field}
$F_q^\eta$

\subsubsection{Polynomial evaluation}
For polynomial evalution in the multiparty computation seen in \autoref{sec:mpc}, we need to evaluate a polynomial $P(x)$ at a point $r \in F_q^\eta$. This is done by evaluating the polynomial at each coefficient and summing the results. The polynomial $P(x)$ is defined as
\begin{align}
  \textstyle\bigcup_{|Q|}(F_q)^{|Q|} \times F_q^\eta & \rightarrow F_q^\eta                 \nonumber                                  \\
  Q(r)                                               & = \textstyle\sum_{i=0}^{|Q|} Q_i \cdot r^{i-1} &  & Q_i \in F_q, r \in F_q^\eta
  \label{eq:mpcpoly}
\end{align}

\section{Linear Secret Sharing Scheme (LSSS)}
\label{sec:sss}

\textit{Secret sharing schemes} (SSS) are a type of cryptographic protocol that allows for the distribution of a secret amongst a group of participants. The secret can only be reconstructed when a sufficient number of shares are combined together. The threshold variant of the SD-in-the-Head protocol relies on a low-threshold linear secret sharing scheme (\textit{LSSS}). Threshold secret sharing schemes allow for the reconstruction of a secret from a subset of shares of length $\ell$, where $\ell$ is the threshold. The threshold allows for the SD-in-the-Head protocol to be more communication efficient, as the amount of shares needed to reconstruct the secret is low.

\begin{definition}
  \label{def:sss}
  \textit{$S$ is a $(\ell,n)$ threshold SSS if it satisfies the following properties}:

  \begin{itemize}
    \item \textbf{Share generation}: Given a secret $s$, the scheme generates $n$ shares $\texttt{share}(s) = [[s]] = [[s_1, s_2, \dots, s_n]]$.
    \item \textbf{Reconstruction}: Given a subset of shares $[[s']]$ of size $\ell$, the scheme can reconstruct the secret $s = \texttt{open}([[s']])$.
  \end{itemize}

\end{definition}

\textit{Linear secret charing schemes}, or $(+,+)$-homomorphic schemes, refers to secret sharing schemes that are linearly homomorphic over some field $\mathbb{F}$ (say the galois field \texttt{GF256} described in \autoref{sec:gf256}). This means that given shares $[[a]]$ and $[[b]]$ we have that
\begin{definition}
  A $(\ell,n)$ threshold SSS is $(+,+)$-homomorphic if for any two secrets $s_1$ and $s_2$ and their shares $[[s_1]]$ and $[[s_2]]$, the sum of the shares $[[s_1]] + [[s_2]] = [[s_{11} + s_{21}, s_{12} + s_{22}, \dots, s_{1n} + s_{2n}]]$ is equal to the share of the sum of the secrets $[[s_1 + s_2]]$ for the same subset of shares.
\end{definition}
\subsection{Shamir's Secret Sharing}
\label{sec:shamir}

Shamir's Secret Sharing scheme \cite{shamir1979share}. Shamir's Secret Sharing is a method for distributing a secret amongst a group of participants, each of which is given a share of the secret. The secret can only be reconstructed when a sufficient number of shares are combined together.

For a secret $s$ and a given security threshold $\ell$, the share $[[s]]$ is generated by sampling a random polynomial of degree $t-1$ with $s$ as the free coefficient. Each participant is given a share of the polynomial evaluated at a point. The secret can be reconstructed by interpolating the polynomial from a sufficient number of shares.

The $(t,n)$ Shamir's polynomial based secret sharing scheme is $(+,+)$-homomorphic in which the addition of two polynomials secrets equals the Lagrange's interpolation of the sum-of-shares for the same subset of shares.

\todo{Write about creating shares, addition}

\section{Zero-Knowledge Proofs}
\label{sec:zkp}

Zero-Knowledge Arguments of Knowledge (ZKAoK) allow a prover to convince a verifier that they knows a certain witness for a statement without revealing any additional information about the witness. \todo{What are they used for..}

ZKAoK protocols have been introduced in multiple variants that each solve specific relational problems with varying levels of communication complexity and prover running times. While many of these perform well for these specific problems, there has long been a need for a well performing generic ZKAoK protocol.

\subsection{MPC-in-the-Head}
\label{sec:mpcith}

Secure Multiparty Computation or MPC describes a cryptographic protocol that allows multiple parties to run a circuit $C$, while no information on inputs is leaked outside of the intended output of $C$. These algorithms can be augmented to ensure correctness, even in the presence of malicious parties. \todo{skriv mere her. Check threshold paper måske?}

The MPC-in-the-Head (MPCitH) framework, introduced by~\cite{ishai2007zero}, uses MPC protocols to construct generic ZKAoK protocols. First, the statement is turned into a circuit $C$. On input $x$, $C$ outputs $y$ iff. $x = w$ for some witness $w$ which is a correct witness for the statement to be proven. The prover simulates the MPC protocol of all the parties \textit{in the head}. The parties each evalutate $C$ on a secret sharing of $w$

The framework benefits from previous efficiency improvements in MPC protocols to improve the efficiency of ZKAoK protocols. Particularly, its possible to achieve \textit{constant-rate} zero knowledge. For an arbitrary circuit $C$ of size $s$ and a bounded fan-in, it is possible to construct a ZKAoK protocol with communication complexity $O(s) + \text{poly}(k)$, for a security parameter $k$. This is an improvement over previous ZKAoK protocols, which had communication complexity $O(ks)$. \todo{write about this in the previous section}.

\subsection{MPC preprocessing}

We first generalize the idea of [KKW18] to work over arithmetic circuits using a variant of the SPDZ MPC protocol [DPSZ12,LN17] and provide a formal proof of security to their "cut-and-choose" preprocessing heuristic. Then, we present a new construction where we replace the "cut-and-choose" mechanism with a "sacrificing"-based approach. While both approaches have similar cost per MPC instance, our "sacrificing"-based approach yields a smaller cheating probability, which means that the number of MPC instances simulated in the proof can be significantly smaller, thus reducing the overall communication footprint. Our scheme is highly flexible in its choice of parameters. In particular, by changing the number of parties in the underlying MPC protocol, one can alternate between achieving low communication and low running time. Our construction only requires efficient standard symmetric primitives, and thus is plausibly post-quantum secure even in the non-interactive case [DFMS19]. The two constructions can be found in \cite{baum2020concretely} \todo{Copied from citation. rewrite this}

\subsubsection{Multiplication and Beaver Triples}
\label{sec:beaver}

\subsection{Verification of a multiplication triple using another}
\label{sec:verify}
Given a random triple $([[a]], [[b]], [[c]])$, it is possible to verify the correctness of a triple $([[x]], [[y]], [[z]])$, i.e., that $z = x \cdot y$, without revealing any information on either of the triples, in the following way \cite{baum2020concretely}.

\begin{enumerate}
  \item The parties generate a random $\epsilon \in \mathbb{F}$.
  \item The parties locally set $[[\alpha]] = \epsilon[[x]] + [[a]], [[\beta]] = [[y]] + [[b]]$.
  \item The parties run \texttt{open}$([[\alpha]])$ and \texttt{open}$([[\beta]])$ to obtain $\alpha$ and $\beta$.
  \item The parties locally set $[[v]] = \epsilon[[z]] - [[c]] + \alpha  \cdot [[b]] + \beta  \cdot [[a]] - \alpha  \cdot \beta$.
  \item The parties run \texttt{open}$([[v]])$ to obtain $v$ and accept iff $v = 0$.

\end{enumerate}
Observe that if both triples are correct multiplication triples (i.e., $z = xy$ and $c = ab$) then the parties will always accept since
\begin{align}
  v & = \epsilon \cdot z - c + \alpha \cdot b + \beta \cdot a - \alpha \cdot \beta                                            \\
    & = \epsilon \cdot xy - ab + (\epsilon \cdot x + a)b + (y + b)a - (\epsilon \cdot x + a)(y + b)                           \\
    & = \epsilon \cdot xy - ab + \epsilon \cdot xb + ab + ya + ba - \epsilon \cdot xy - \epsilon \cdot xb - ay - ab           \\
    & = (\epsilon \cdot xy - \epsilon \cdot xy) + (ab - ab) + (\epsilon \cdot xb - \epsilon \cdot xb) + (ya - ay) + (ba - ab) \\
    & = 0
\end{align}

\subsection{Error probability}

\begin{lemma}
  If $([[a]], [[b]], [[c]])$ or $([[x]], [[y]], [[z]])$ is an incorrect multiplication triple then the parties output \texttt{accept} in the sub-protocol above with probability $\frac{1}{|\mathbb{F}|}$.
\end{lemma}

\todo{Proof of lemma and solution}

\section{Fiat-Shamir Heuristic}
\label{sec:fiatshamir}

\todo{Turning the ZKAoK into a signature scheme}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Specification}
\label{ch:spec}
more detailed description of the algorithm
e.g. how we sampled I[e] witness challenge
table of spec params (with our code naming and different categories)

\section{Merkle Tree Commitment}

\todo{Can we use Haraka v2}

\section{Hashing and XOF}

\todo{Write about Shake, Keccak} and how we initiate the hash function and XOF

\section{MPC computation}

The computation is based on HVZKAoK Protocol using imperfect preprocessing and sacrificing. Section 3.3 \cite{baum2020concretely}.

A toy example of the computation protocol computations, can be seen in~\autoref{fig:mpc}. We have the two computation methods. Here for 1 split and 1 evaluation point. This means that we have only value for each challenge and beaver triple. Note that any arithmetic is run in GF256, so addition and subtraction are both \texttt{XOR} and multiplication is modulus $x^8 + x^4 + x^3 + x + 1$. Furthermore, for negation we have that $-a = a$.

\begin{figure}
  \makebox[\textwidth]{
    \fbox{\begin{minipage}[t]{.45\textwidth}
        \noindent \texttt{PartyComputation}
        \begin{flalign*}
           & \textit{Input: }                                                               \\
           & (s_a, Q', P, a, b, c), (\overline{\alpha}, \overline{\beta}), (H', y)          \\
           & (\epsilon, r), \texttt{with\_offset}                                           \\
           & \textit{Output: }                                                              \\
           & (\alpha, \beta, v)                                                             \\\\
           & Q = Q'_1\text{ if \texttt{with\_offset} else }Q'_0                             \\
           & S = (s_a | y + H's_a) \text{ if \texttt{with\_offset} else } (s_a | H's_a)     \\
           & v = -c                                                                         \\
           & \alpha = \epsilon \cdot Q(r) + a                                               \\
           & \beta = S(r) + b                                                               \\
           & v \mathrel{{+}{=}} \epsilon \cdot F(r) \cdot P(r)                              \\
           & v \mathrel{{+}{=}} \overline{\alpha} \cdot b + \overline{\beta} \cdot a        \\
           & v \mathrel{{+}{=}} - \alpha \cdot \beta \text{ \ \ \ if \texttt{with\_offset}}
        \end{flalign*}
      \end{minipage}}
    \hfill
    \noindent
    \fbox{\begin{minipage}[t]{.45\textwidth}
        \noindent \texttt{InverseComputation}
        \begin{flalign*}
           & \textit{Input: }                                                                 \\
           & (s_a, Q', P), (\alpha, \beta, v), (\overline{\alpha}, \overline{\beta}), (H', y) \\
           & (\epsilon, r), \texttt{with\_offset}                                             \\
           & \textit{Output: }                                                                \\
           & (a, b, c)                                                                        \\\\
           & Q = Q_1\text{ if \texttt{with\_offset} else }Q_0                                 \\
           & S = (s_a | y + H's_a) \text{ if \texttt{with\_offset} else } (s_a | H's_a)       \\
           & c = -v                                                                           \\
           & a = \alpha - \epsilon \cdot Q(r)                                                 \\
           & b = \beta - S(r)                                                                 \\
           & c \mathrel{{+}{=}} \epsilon \cdot F(r) \cdot P(r)                                \\
           & c \mathrel{{+}{=}} \overline{\alpha} \cdot b + \overline{\beta} \cdot a          \\
           & c \mathrel{{+}{=}} - \alpha \cdot \beta \text{ \ \ \ if \texttt{with\_offset}}
        \end{flalign*}
      \end{minipage}}}
  \caption{Simplified version of the MPC party computation and inverse computation. $Q_0$ means that $Q$ is completed with a $0$ for leading coefficient. Furthermore, $F$ is precomputed. Note that all arithmetic is done in $\mathbb{F}_q = GF256$. All elements are in $\mathbb{F}_q^\eta$ except for the coefficients of $Q$, $S$ and $P$ which are in $\mathbb{F}_q$.}
  \label{fig:mpc}
\end{figure}
\bigskip

Note that the

If we first instantiate an input $i$ and one random input $i^*$ (like the \texttt{input\_coef}).Then the input share is generated by adding the two. Similar, but simpler, to the input share generation of Algorithm 12, line 13 of the specification.
\begin{align*}
  i             & = (s_a, Q, P, a,b,c)                                             \\
  i^*           & = ({s_a}^*, Q^*, P^*, a^*,b^*,c^*)                               \\
  [i] = i + i^* & = ({s_a} + {s_a}^*, Q + Q^*, P + P^*, a + a^*, b + b^*, c + c^*) \\
                & = ([s_a], [Q], [P], [a], [b], [c])                               \\
  \texttt{chal} & = (\epsilon, r)                                                  \\
  \texttt{pk}   & = (H', y)
\end{align*}
We also compute the plain broadcast share of the input as per Algorithm 12, line 18. Note that $\overline{v}$ is computed to zero and therefore removed from the computation in the implementation.
\begin{align*}
  (\overline{\alpha},\ \overline{\beta})         & =
  \texttt{PartyComputation}(i,\ (\overline{\alpha}, \overline{\beta}),\ \texttt{chal},\ \texttt{pk},\ \texttt{true})                                                                                   \\\\
  \overline{\alpha}                         =    & \epsilon \cdot Q_1(r) + a                                                                                                                           \\
  \overline{\beta}                          =    & S_y(r)  + b                                                                                                                                         \\
  \overline{v}                            =      & -c + \epsilon \cdot F(r) \cdot P(r) + \overline{\alpha} \cdot b + \overline{\beta} \cdot a  - \overline{\alpha} \cdot \overline{\beta}              \\
  \overline{v}                            =      & -c + \epsilon \cdot F(r) \cdot P(r) + (\epsilon \cdot Q_1(r) + a) \cdot b + (S_y(r)  + b) \cdot a  - (\epsilon \cdot Q_1(r) + a) \cdot (S_y(r) + b) \\
  \overline{v}                            =      & -c + \epsilon \cdot F(r) \cdot P(r)                                                                                                                 \\
                                                 & + \epsilon \cdot Q_1(r) \cdot b + c + S_y(r) \cdot a + c                                                                                            \\
                                                 & - \epsilon \cdot Q_1(r) \cdot S_y(r) - \epsilon \cdot Q_1(r) \cdot b - a \cdot S_y(r) - c                                                           \\
  \overline{v}                                 = & \ 0
\end{align*}
We then compute a broadcast share from the randomness and the broadcast, as per Algorithm 12, line 21.
\begin{align*}
  (\alpha^*, \beta^*, v^*) & = \texttt{PartyComputation}(i^*, (\overline{\alpha},
  \overline{\beta}), \texttt{chal}, \texttt{pk}, \texttt{false})                  \\\\
  \alpha^*                 & = \epsilon \cdot {Q^*}_0(r) + a^*                    \\
  \beta^*                  & =  {S^*}_0(r) + b^*
\end{align*}
This broadcast share is sent to the verifier along with the truncated input share (removing the beaver triples). The verifier then needs to recompute the input share beaver triples using the \texttt{InverseComputation} function. First we add the input share to the broadcast share as per Algorithm 13, line 8.
\begin{align*}
  (\alpha', \beta', v') & = (\alpha^*, \beta^*, v^*) + (\overline{\alpha},\ \overline{\beta}, 0)
  = (\alpha^* + \overline{\alpha}, \beta^* + \overline{\beta}, v^* + 0)                          \\\\
  \alpha'               & = \epsilon \cdot {Q^*}_0(r) + a^* + \overline{\alpha}                  \\
                        & = \epsilon \cdot {Q^*}_0(r) + a^* + \epsilon \cdot Q_1(r) + a          \\
  \beta'                & = {S^*}_0(r) + b^* + \overline{\beta}                                  \\
                        & = {S^*}_0(r) + b^* + S_y(r) + b                                        \\
\end{align*}
Next, the verifier computes the inverse of the broadcast share to recompute $([a], [b], [c])$ using the \texttt{InverseComputation} function. This is done as per Algorithm 13, line 10.
\begin{align*}
  (a', b', c') & = \texttt{InverseComputation}([i], (\alpha', \beta', v'),
  (\overline{\alpha}, \overline{\beta}), \texttt{chal}, \texttt{pk}, \texttt{true})                                                  \\\\
  a'           & = \alpha' - \epsilon \cdot {[Q]}_1(r)                                                                               \\
               & = \epsilon \cdot {Q^*}_0(r) + a^* + \epsilon \cdot Q_1(r) + a - \epsilon \cdot {[Q]}_1(r)                           \\
               & = \epsilon \cdot {Q^*}_0(r) - \epsilon \cdot {[Q]}_1(r) + \epsilon \cdot Q_1(r) + [a]                               \\
               & = \epsilon \cdot ({Q^*}_0(r) - {[Q]}_1(r) +  Q_1(r)) + [a]                                                          \\
               & = \epsilon \cdot (Q^*_0(r) +  Q^*_0(r)) + [a]                                             &  & \autoref{eq:mpcpoly} \\
               & = [a]                                                                                     &  & \autoref{eq:mpcpoly} \\
  b'           & = \beta' - {[S]}_y(r)                                                                                               \\
               & = {S^*}_0(r) + b^* + S_y(r) + b - {[S]}_y(r)                                                                        \\
               & = {S^*}_0(r) - {[S]}_y(r) + S_y(r)  + [b]                                                                           \\
               & = {S^*}_0(r) - S^*_0(r)  + [b]                                                            &  & \autoref{eq:mpcpoly} \\
               & = [b]                                                                                     &  & \autoref{eq:mpcpoly} \\
\end{align*}
\todo{Want to explain the above in a more detailed manner? Specifically ${Q^*}_0(r) - {[Q]}_1(r) = Q_1(r)$}

\section{Security}

The security analysis of the SD-in-the-Head signature scheme is based on the proposed standardization requirements from the 2022 NIST call for proposals of non-lattice based signature schemes \cite{nistcall}. Therefore, as a preliminary, we will describe the reasoning and requirements of the NIST standardization process.

With the development of new quantum algorithms and unknowns in the capacities of the future quantum computers, there remain large uncertainties in estimating the security of the algorithms. To combat these uncertainties, NIST proposed for the 2022 stadardization effort, to define the security of submissions in a range of five categories. Each, with an easy-to-analyze cryptographic primitive providing the lower bound for a variety of metrics deemed relevant to practical security. The SD-in-the-Head specification provides security parameters adhering to categories one, three and five.

\begin{definition}
  \label{def:nistsec}
  Any attack that breaks the relevant security definition must require computational resources comparable to or greater than those required for key search on a block cipher with a 128-bit (e.g. AES-128), 192-bit (e.g. AES-192) and 256-bit (e.g. AES-256) for categories one, three and five respectively.
\end{definition}

In terms of quantum security, the complexity and capability of quantum algorithms are measured in terms of quantum circuit size, i.e. the number of quantum gates in the quantum circuit. In order to estimate the quantum security of the signature protocols, circuit size can be compared to the resources required to break the security of \autoref{def:nistsec}. Therefore,
according to the proposal by NIST, the SD-in-the-Head specification provides security metrics in terms of quantum circuit depth to optimal key recovery for AES-128, AES-192 and AES-256 for categories one, three and five respectively. These are estimated to be $2^{143}$, $2^{207}$ and $2^{272}$ classical gates~\cite{nistcall}.

\subsection{Security Definition}

The SD-in-the-Head signature scheme upholds the \textbf{E}xistential \textbf{U}n\textbf{f}orgeability under \textbf{C}hosen \textbf{M}essage \textbf{A}ttack (EUF-CMA) security property for digital signature schemes as this is the type of attack that NIST will evaluate signature proposals~\cite{nistcall,aguilarsyndrome11}. EUF-CMA works as the following game:

\begin{enumerate}
  \item The challenger generates a key pair $(pk, sk)$ and sends $pk$ to the adversary.
  \item The adversary is then allowed to query a signing oracle for signatures of chosen messages $(m_1, ..., m_r)$ and receives valid signatures $(\sigma_1, ..., \sigma_r)$. For the NIST evaluation it is assumed that the adversary can query the signing oracle for up to $2^{64}$ chosen messages according to the adversary's running time. However, there is no requirement on the timing of the queries.
  \item The adversary then outputs a pair $(m^*, \sigma^*)$. The adversary wins if the following holds
        \begin{enumerate}
          \item $m^*$ has not been queried to the signing oracle.
          \item The pair $(m^*, \sigma^*)$ is a valid signature for $m^*$ under $pk$.
        \end{enumerate}
\end{enumerate}

\begin{table}[h]
  \label{tab:secparam}
  \centering
  \def\arraystretch{1.5}%  1 is the default, change whatever you need
  \begin{tabular}{cccccccccccccc}
    \specialrule{.1em}{.05em}{.05em}
    \multicolumn{2}{c}{\textbf{NIST security}} &      & \multicolumn{5}{c}{\textbf{SD parameters}} &     & \multicolumn{5}{c}{\textbf{MPCitH Parameters}}                                                             \\ \cline{1-2} \cline{4-8} \cline{10-14}
    Category                                   & Bits &                                            & $q$ & $m$                                            & $k$ & $w$ & $d$ &  & N   & $\ell$ & $\tau$ & $\eta$ & $t$ \\ \hline
    \textbf{I}                                          & 143  & \textit{}                                  & 256 & 242                                            & 126 & 87  & 1   &  & $q$ & 3      & 17     & 4      & 7   \\
    \textbf{III}                                        & 207  &                                            & 256 & 376                                            & 220 & 114 & 2   &  & $q$ & 3      & 26     & 4      & 10  \\
    \textbf{V}                                          & 272  &                                            & 256 & 494                                            & 282 & 156 & 2   &  & $q$ & 3      & 34     & 4      & 13  \\ \specialrule{.1em}{.05em}{.05em}
  \end{tabular}
  \caption{Security parameters for the SDitH protocol for categories one, three and five~\cite{aguilarsyndrome11}.}
\end{table}

\begin{table}[h]
  \label{tab:hashparam}
  \centering
  \def\arraystretch{1.5}%  1 is the default, change whatever you need
  \begin{tabular}{clll}
    \specialrule{.1em}{.05em}{.05em}
         & \multicolumn{1}{c}{\textbf{I}} & \multicolumn{1}{c}{\textbf{III}} & \multicolumn{1}{c}{\textbf{V}} \\ \cline{2-4}
    Hash & SHA3-256                       & SHA3-384                         & SHA3-512                       \\
    XOF  & SHAKE-128                      & SHAKE-256                        & SHAKE-256                      \\ \specialrule{.1em}{.05em}{.05em}
  \end{tabular}
  \caption{Hash and XOF functions used in the SDitH protocol for categories one, three and five~\cite{aguilarsyndrome11}.}
\end{table}

\subsection{Assumptions}
\label{sec:assumptions}
The SD-in-the-Head protocol is secure under the following assumptions:

Syndrome Decoding instances cannot be solved in complexity lower than $2^\kappa$ corresponding to the complexity of breaking AES by exhaustive search (see \autoref{def:nistsec}) in terms of quantum circuit size. For this, $\kappa$ is defined as $143$, $207$ and $272$ for the categories \cite{nistcall}. Furthermore, the XOF primitive used is secure with 128-bit, 192-bit, 256-bit security levels for each of the categories respectively. Finally, the Hash function used \textit{behaves as random oracle}. Specifically, security holds in Random Oracle Model (ROM) and Quantum Random Oracle Model (QROM).

\subsection{Security of the Syndrome Detection Problem}
\label{sec:sdsec}

Recall the definition of the syndrome detection problem from \autoref{def:syndrome}. The hardness of the SD problem is well established and the coset variant used in the SD-in-the-Head signature scheme, has been shown to be \textit{NP-complete}~\cite{berlekamp1978inherent,aguilarsyndrome11}. Furthermore, a brute force attack of guessing $x$ would require finding a unique correct solution in $\binom{m}{w} q^w$ which is infeasible for the parameters outlined in the specification. As an example, for category one, the number of possible solutions are $\approx 7.7 \times 10^{276}$. There exists more sophisticated algorithms for solving the SD problem, such as the Generalized Birthday Algorithms (GBA) and Information Set Decoding (ISD)~\cite{prange1962use}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementation}
\label{ch:impl}

Tooling and language feaures (rust, criterion, rayon)
code sections
code re-usability with traits for categories.

const generics vs inline mutability (benchmarking?, nightly?)
compiling constants for categories

can we use other hashes that still provide the same security assumption from \autoref{sec:assumptions} as post-quantum security (Xoodyak, KangarooTwelve, Haraka v2)

\section{Rust}
\cite{nistsaferlanguages}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Benchmarks}
\label{ch:bench}
diaries of benchmarks.
discussion of results

Test on both mac and linux.
nightly vs stable rust
different hashes
benching at different tags
parallelisation, test for amount of cores, 2, 4, 8, 16
no turbo boost (max 2.6 GHz)
cycles per bytes
compare ours to the optimised reference

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusion}
\label{ch:conclusion}

wrap up and pose future work
what should people continue with
point to round 2 NIST
work in context of timeline

\todo{conclude on the problem statement from the introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\addcontentsline{toc}{chapter}{Bibliography}
\bibliographystyle{plain}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\appendix
\chapter{The Technical Details}

\todo{\dots}

\end{document}
